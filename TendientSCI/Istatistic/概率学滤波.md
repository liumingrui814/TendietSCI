### 贝叶斯滤波

贝叶斯滤波的数学来源想必是已经了然于心了，因此在这里主要讨论一下《概率机器人》一书中为何要将贝叶斯滤波表示为
$$
bel({\boldsymbol{x}_t}) = \eta p(z_t|\boldsymbol{x_t})\bar{bel}(\boldsymbol{x_t})
$$
《概率机器人》一书中，对贝叶斯后验的描述是  $p(\boldsymbol{x}_t|z_{1:t},\boldsymbol{u}_{1:t})$, 在纯建图时由于并不存在控制模型$\boldsymbol{u}$, 模型可以简化为$p(\boldsymbol{x}_t|z_{1:t})$(在融合信息定位时当然不能这样考虑)，即原始的贝叶斯滤波公式为：
$$
p(\boldsymbol{x}|z_{1:t}) = \frac{p(z_t|\boldsymbol{x}_t,z_{1:t-1})p(\boldsymbol{x}|z_{1:t-1})}{p(z_t|z_{1:t-1})}
$$

> 注意到$z_{1:t-1}$是所有$p$的条件概率，在列写基本方程时$z_{1:t-1}$都是作为条件写出

由于$p(z_t|\boldsymbol{x}_t,z_{1:t-1})=p(z_t|\boldsymbol{x}_t)$,即默认前面的观测$z_{1:t-1}$并不会影响$z_t$, 即最后的式子可以写成：
$$
p(\boldsymbol{x}|z_{1:t}) = \frac{p(z_t|\boldsymbol{x}_t)p(\boldsymbol{x}|z_{1:t-1})}{p(z_t)}
$$
可以看到分母上的$p(z_t)$是个很奇怪的量，即观测出现的概率，用全概率公式表示的话则可以写成$p(z_t)=\sum_i p(z_t|\boldsymbol{x}_i)p(\boldsymbol{x}_i)$, $p(z_t|\boldsymbol{x}_i)$是固定的函数，其在全时间段满足一致的规律，$p(\boldsymbol{x_i})$在$t$时间戳的描述应当也是固定的，因此$p(z_t)$被认为是一个定值，从而可以直接用归一化因子$\eta$替代，在静态二值贝叶斯滤波系统中，由于只有$\boldsymbol{x},\neg\boldsymbol{x}$两种状态，评估指标被换成了$l_t(\boldsymbol{x}) = \frac{p(x|z_{1:t})}{p(\neg x|z_{1:t})}$, 从而数学意义上的消除了归一化因子，这是另一种滤波方法。

$\bold{eg}$: 《概率机器人》上举了机器人检测开门的例子，不妨在这里迭代地利用$bel({\boldsymbol{x}_t}) = \eta p(z_t|\boldsymbol{x_t})\bar{bel}(\boldsymbol{x_t})$进行推演：

- $p(open)=p(close)=0.5$
- $p(z=open|open)=0.6, p(z=close|open)=0.4$
- $p(z=open|close)=0.2, p(z=close|close)=0.8$

在$t=1$时机器人观察到门是开的，则得到门是开的的置信度与门是关的置信度：
$$
p(\boldsymbol{x}=open|z_1)=\eta p(z_1|\boldsymbol{x}=open)p(\boldsymbol{x}=open)=0.3\eta\\
p(\boldsymbol{x}=close|z_1)=\eta p(z_1|\boldsymbol{x}=close)p(\boldsymbol{x}=close)=0.1\eta\\
$$
则由$p(\boldsymbol{x}=close|z_1)+p(\boldsymbol{x}=open|z_1)=1$可得$\eta=2.5$，对应的贝叶斯公式的$p(z_1)=0.4$, 可以注意到$p(z_1)=p(z_1|open)p(open)+p(z_1|close)p(close)=0.6*0.5+0.2*0.5=0.4$, 与全概率公式描述相同。

在$t=2$时第二次观察到门是开的，则又得到门是开的的置信度与门是关的置信度：
$$
p(\boldsymbol{x}=open|z_1,z_2)=\eta p(z_2|\boldsymbol{x}=open)p(\boldsymbol{x}=open|z_1)=0.75*0.6\eta =0.45\eta \\
p(\boldsymbol{x}=close|z_1,z_2)=\eta p(z_2|\boldsymbol{x}=close)p(\boldsymbol{x}=close|z_1)=0.2*0.25 = 0.05\eta\\
$$
则得到此时的$\eta=2$, 对应贝叶斯公式的$p(z_2)=0.5$, 此时按照原理则有$p(z_2)=p(z_2|open)p(open|z_1)+p(z_2|close)p(close|z_1)=0.6*0.75+0.2*0.25=0.05$

因此我们可以注意到，$\eta$作为归一化因子是一个随时序变化的量而并不是一个关于任意$t$都固定的定值，这是因为全概率公式$p(z_t)=\sum_i p(z_t|\boldsymbol{x}_i)p(\boldsymbol{x}_i)$中$p(\boldsymbol{x}_i)=p(\boldsymbol{x}_i|z_{1:t-1})$是一个不断更新的量，每个$t$都会不一样，假如在更新过程中选择忽略$\eta$的变化，贝叶斯公式不断的累积最终会导致式子失去归一化的性质，不过许多论文仍然采用忽略$\eta$的方式，因为根据他们的设计，$p(\boldsymbol{x}|z_{1:t}),p(\neg \boldsymbol{x}|z_{1:t})$二者不用一致的贝叶斯公式，且最终的比较是比较二者的相对关系，从而使更新不需要严格地用贝叶斯滤波，这也是一种有趣的方法。

### 卡尔曼滤波

我们在先前讨论了多元正态分布作为一个椭圆分布在样本层面的性质（即$\Sigma$矩阵特征值与特征向量的意义与多元正态分布的概率密度函数$p(\boldsymbol{x})=\frac{1}{(2\pi)^{m/2}\|\Sigma\|^{1/2}}\exp(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^T\Sigma^{-1}(\boldsymbol{x}-\boldsymbol{\mu}))$在函数形式、函数形状特点上的意义）从而具备了讨论一个具有高斯噪声的控制-观测模型的可能性。

> 在《概率机器人》一书中，前面的系数项为$\det(2\pi \Sigma)^{1/2}$,这种表示方法也是对的，是种更能体现多元特性的表示方法

卡尔曼滤波假设状态满足状态空间方程和状态观测方程：
$$
\left\{
\begin{align}
\boldsymbol{x_t} &= A_t\boldsymbol{x}_{t-1}+B_t\boldsymbol{u}_t+\boldsymbol{\varepsilon}_t, \qquad \boldsymbol{\varepsilon} \sim
\mathcal{N}(0,\boldsymbol{R}_t) \\
\boldsymbol{z_t} &= C_t \boldsymbol{x}_t+\boldsymbol{\delta}_t \qquad \boldsymbol{\delta}_t \sim \mathcal{N}(0,\boldsymbol{Q}_t)
\end{align}
\right.
$$
同时初始状态$\boldsymbol{x}_0 \sim \mathcal{N}(\boldsymbol{\mu}_0, \Sigma_0)$也满足正态分布的形式，那么对于贝叶斯公式的任务，即从$p(\boldsymbol{x}_{t-1}|z_{1:t-1}) \to p(\boldsymbol{x}_t|z_{1:t})$, 卡尔曼滤波则是给出了基于线性状态系统+高斯分布模型的后验更新方法。

#### 获得先验$\mathbf{\bar{\mu}_t,\bar{\Sigma}_t}$

根据正态分布的性质，正态分布的线性组合同样满足正态分布，对于状态转移方程$\boldsymbol{x_t} = A_t\boldsymbol{x}_{t-1}+B_t\boldsymbol{u}_t+\boldsymbol{\varepsilon}_t$, 里面的$\boldsymbol{x}_{t-1}，\boldsymbol{\varepsilon}_t$是正态分布,$B\boldsymbol{u}_t$是个漂移，因此状态转移得到的期望很好写出，即：
$$
\bar{\boldsymbol{\mu_t}} = A_t\boldsymbol{\mu}_{t-1}+B_t\boldsymbol{u}_t  \qquad (1)
$$
而方差则满足多元正态分布函数的叠加规律，即
$$
\bar{\Sigma}_t = A_t\Sigma_{t-1}A_t^T + \boldsymbol{R}_t \qquad (2)
$$
此即卡尔曼滤波的先验评估公式.

#### 获得后验$\boldsymbol{\mu}_t, \boldsymbol{\Sigma}_t$

在得到$\bar{\boldsymbol{\mu}},\bar{\boldsymbol{\Sigma}}$之后，则结合贝叶斯公式对后验概率进行更新，即更新
$$
bel(\boldsymbol{x}_t) = \eta p(z_t|\boldsymbol{x_t}) \overline{bel}(\boldsymbol{x}_t)
$$
其中$p(z_t|\boldsymbol{x_t})$即观测模型，满足$p(z_t|\boldsymbol{x_t}) \sim \mathcal{N}(C\boldsymbol{x}_t, \boldsymbol{Q}_t)$, $\overline{bel}(\boldsymbol{x}_t)$是由状态方程提供的先验概率，即$\overline{bel}(\boldsymbol{x}_t) \sim \mathcal{N}(\bar{\boldsymbol{\mu_t}}, \overline{\Sigma}_t)$.则对于两个概率密度函数，其乘积也就是两个负指数函数的乘积，满足形式$\exp(t1)\times\exp(t2) = \exp(t1+t2)$, 则$bel(\boldsymbol{x}_t)$可以进一步写成
$$
\begin{align}
bel(\boldsymbol{x}_t) &= \eta p(z_t|\boldsymbol{x_t}) \overline{bel}(\boldsymbol{x}_t) \\
&=\eta \exp(\frac{1}{2}(z_t-C\boldsymbol{x}_t)^T\boldsymbol{Q}_t^{-1}(z_t-C\boldsymbol{x}_t)+\frac{1}{2}(\boldsymbol{x}_t-\bar{\boldsymbol{\mu_t}})^T\bar{\Sigma}_t^{-1}(\boldsymbol{x}_t-\bar{\boldsymbol{\mu_t}}))
\end{align}
$$
由于该指数项也是个半正定二次型，因此也满足一个标准正态分布分布函数的形式，则不妨将此二次型先简化为$\mathcal{J} = \frac{1}{2}(x-\boldsymbol{\mu})^T\Sigma^{-1}(x-\boldsymbol{\mu})$,其满足：
$$
\left\{
\begin{align}
\frac{\partial \mathcal{J}}{\partial \boldsymbol{x}} &= \Sigma^{-1}(\boldsymbol{x}_t-\boldsymbol{\mu}) = -C_t^T\boldsymbol{Q}_t^{-1}(z_t-C_t\boldsymbol{x}_t)+\overline{\Sigma}_t^{-1}(\boldsymbol{x}_t-\bar{\boldsymbol{\mu_t}}) \\
\frac{\partial^2 \mathcal{J}}{\partial \boldsymbol{x}^2} &= \Sigma^{-1} = C_t^T\boldsymbol{Q}_t^{-1}C_t + \overline{\Sigma}_t^{-1}
\end{align}
\right.
$$


> 注意，对于向量函数求导有$(A^TX)'=A$,在一阶导数转二阶导数时，由于$\Sigma^{-1} = C_t^T\boldsymbol{Q}_t^{-1}C_t + \overline{\Sigma}_t^{-1}$一整个都是对称的，则转置与本身没有区别，从而让人觉得这就是$X$的系数，这里注意一下

则可以直接写出后验的协方差$\Sigma_t =(C_t^T\boldsymbol{Q}_t^{-1}C_t + \overline{\Sigma}_t^{-1}))^{-1} $, 而对于期望$\boldsymbol{\mu}$则有$\boldsymbol{\mu}$对应一阶导数$\frac{\partial \mathcal{J}}{\partial \boldsymbol{x}}$的零点，即
$$
-C_t^T\boldsymbol{Q}_t^{-1}(z_t-C_t\boldsymbol{x}_t)+\overline{\Sigma}_t^{-1}(\boldsymbol{x}_t-\bar{\boldsymbol{\mu_t}}) = 0\\
(\overline{\Sigma}_t^{-1}+ C_t^T\boldsymbol{Q}_t^{-1}C_t )\boldsymbol{x}_t =  C_t^T\boldsymbol{Q}_t^{-1}z_t+\overline{\Sigma}_t^{-1}\bar{\boldsymbol{\mu_t}}\\
\boldsymbol{x}_t = \Sigma_t(C_t^T\boldsymbol{Q}_t^{-1}z_t+\overline{\Sigma}_t^{-1}\bar{\boldsymbol{\mu_t}})
$$
则定义卡尔曼增益$K_t=\Sigma_tC_t^T\boldsymbol{Q}_t^{-1}$, 有$\boldsymbol{\mu}_t = Kz_t+\Sigma_t \bar{\Sigma}_t^{-1}\bar{\mu}_t$, 则由$\bar{\Sigma}_t^{-1} = \Sigma_t^{-1}-C_t^T\boldsymbol{Q}_tC_t$,带入有：
$$
\boldsymbol{\mu_t} = \bar{\boldsymbol{\mu}_t}+K_t(z_t - C_t\bar{\boldsymbol{\mu}_t})  \qquad (4)
$$
则此时已经完备地描述出了$\Sigma_t,\boldsymbol{\mu}_t$, 不过为了进一步简化表示，考虑将$\Sigma_t$用更简单的方式表示出来，这全是计算方法，对理论推导的意义不大，因此我不打算在这里花时间去简化地表示$\Sigma_t$, 结合上面的所有推导，则最终能得到卡尔曼滤波最完备的五条公式：
$$
\left\{
\begin{align}
\bar{\boldsymbol{\mu_t}} &= A_t\boldsymbol{\mu}_{t-1}+B_t\boldsymbol{u}_t  \qquad & (1) \\
\bar{\Sigma}_t &= A_t\Sigma_{t-1}A_t^T + \boldsymbol{R}_t \qquad &  (2) \\
K_t &= \bar{\Sigma}_tC_t^T(C_t\bar{\Sigma}_tC_t^T+Q_t)^{-1}    \qquad & (3)\\
\boldsymbol{\mu_t} &= \bar{\boldsymbol{\mu}_t}+K_t(z_t - C_t\bar{\boldsymbol{\mu}_t}) & \qquad (4)\\
\Sigma_t &= (I-K_tC_t)\bar{\Sigma}_t \qquad & (5)

\end{align}
\right.
$$
此即卡尔曼滤波公式推导的全部过程。

### 粒子滤波

在面对定位或是特征点等数学模型更加复杂的问题时，模型化的$KF$不一定能够很好地发挥本领，从而需要进一步介绍基于离散状态滤波的粒子滤波算法，这同样是一个基于贝叶斯滤波的滤波框架，但具有离散的表述。

粒子滤波利用状态集：
$$
\mathcal{X_t}=\{\boldsymbol{x}_t^{[1]},\boldsymbol{x}_t^{[2]},...,\boldsymbol{x}_t^{[M]}\}
$$
来表述状态的分布情况，从而将概率分布描述的状态变成了统计学的描述，即用一组数量为$M$的状态样本去表述状态的分布。理想情况下$\boldsymbol{x}_t \sim p(x_t|z_{1:t},u_{1:t})$. 则对于$\mathcal{X}_t$,$\boldsymbol{x_t}(estimate) = E(\mathcal{X_t})$。这个状态集需要满足蒙特卡洛的规定，即状态集的频率需要能够正确地反应分布的概率，即：
$$
\frac{1}{M}\sum_{m=1}^M I(x^{[m]}\in A) = \int_A g(x)dx
$$
其中$ I(x^{[m]}\in A)$为二值函数，$x\in A$时为1，反之为0，即$x$在一个区间出现的频率需要与概率分布在这个区间的概率一致（这当然是$M\to \infty$时才行，粒子滤波只是做样本上的近似表述）

而倘若有另一个概率密度函数$f(x)$, 满足$g(x)$概率-频率关系的样本集$\mathcal{X}$需要变换到满足$f(x)$的概率-频率关系，则一种显然的方法即是根据$f(x),g(x)$的关系为每个$x\in \mathcal{X}$ 添加一个权重$w$, 使得
$$
\frac{1}{M}\sum_{m=1}^M I(x^{[m]}\in A)w^{[m]} = \int_A f(x)dx
$$
但在例子滤波中如果单纯使用$x\times w$来利用加权表示概率分布，则会出现一些$w$很小从而使得这些状态不再具有参考意义的情况，从而拖垮整个算法的性能。因而粒子滤波同样需要解决动态调整$x$的分布的问题，这被称为重采样（$re-sampling$）

因而在理解粒子滤波时，需要了解的问题也就变为：

- $\mathcal{X}$的分布如何通过状态模型$p(\boldsymbol{x}|\boldsymbol{u}_t,z_{1:t-1})$与观测模型$p(\boldsymbol{z}_t|\boldsymbol{x}_t)$生成和更新

#### 滤波器

由于贝叶斯滤波是个递归的估计，$\mathcal{X}_t$可以直接利用$\mathcal{X}_{t-1}$的状态通过状态转移模型$p(\boldsymbol{x}|\boldsymbol{u}_t,z_{1:t-1})$获得，这部分相当于粒子滤波的先验，即$\overline{\mathcal{X}_t} = f(\mathcal{X}_{t-1})$, 而观测则同样满足贝叶斯滤波更新的方式：
$$
p(\boldsymbol{x}_t|\boldsymbol{z}_{1:t},\boldsymbol{u}_{1:t}) = \eta p(\boldsymbol{z}_t|\boldsymbol{x}_t)p(\boldsymbol{x}_t|\boldsymbol{u}_t,z_{1:t-1})
$$
由于当前的分布是一组数量为$M$的例子构成的，$\eta$没有意义（因为只需要获得$\mathcal{X}$在各个状态区间的分配，从而获得比值关系就足够）。

- $p(\boldsymbol{x}|\boldsymbol{u}_t,z_{1:t-1})$是上一轮计算得到的粒子集合的状态转移$\overline{\mathcal{X}_t}$, 

- $p(\boldsymbol{z}_t|\boldsymbol{x}_t)$则相当于在获得$\boldsymbol{z}_t$后对每个$\overline{\mathcal{X}}_t$中估计的状态$\boldsymbol{x}$进行了一次打分

- 得到$\overline{\mathcal{X}},p(z_t|x_t)$后，利用重采样来调整状态集的分布，从而得到$p(z|x)$约束的新的分布的状态集。
- 新的状态集$\mathcal{X}_t$的期望$E(x_t)$也即新估计的状态，其分布也就是下一轮估计时状态递归的输入。

#### 重采样

对于每个$x_t \in \mathcal{X}$,都可以根据观测模型计算一个$p(z_t|x_t)=w$, 按道理来说只需要保证新的分布中$p(x_t) \propto w(x_t)$即能够得到一个观测模型约束的分布，但$p(x_t) \propto w(x_t)$的计算会产生小数，不利于样本的再分布，从而利用如下的方法进行重采样

- $c=w_t^{[1]}, r\sim rand(0, 1/M), i=1$
- 对于$m \in [1,M]$，计算$U=r+(m-1)/M$, 此时$U$表示跨过样本的比例， 由于采样满足$p(x_t) \propto w(x_t)$, 则$U$与$w$的分布函数$\sum{w}$应该基本保持一致
- 当$U < \sum_{j=0}^i{w}$时,说明还需要填入状态$x_j$, 使得加入$x_j$的比例与$ w_i$保持比例上一致。直到$U> \sum_{j=0}^i{w}$, 此时则更新$w$的累积分布概率，即$i=i+1$, 从而继续用样本$x$填入使得$U,\sum w$继续保持在相同的水平。
- 遍历完样本$\overline{\mathcal{X}}$后即完成了一轮重采样。

重采样的本质就是将$x\in \overline{\mathcal{X}}$按照$x\propto w$ 的比例进行重复或剔除（满足整数样本的计算约束），以实现观测模型对原本分布的矫正。

#### 实践粒子滤波：Landmark-Localization

我们有必要通过实物实验来进一步了解粒子滤波的噪声模型以及在实际应用中采样、状态转移等模型的实际表现。 Landmark-Localization是类似GPS的一种定位方法，机器人在一个点观测多个landmarks, 得到其与landmarks的距离，结合多个landmarks的距离可以唯一地定位到机器人的位置（当然距离的观测是存在噪声的）。

##### 运动模型

现在假设一个机器人的运动模型如下所示：
$$
\begin{align}
\begin{bmatrix}
x_{t+1}\\y_{t+1}\\ \theta_{t+1}\\ v_{t+1}
\end{bmatrix}
=
\begin{bmatrix}
1& 0& 0& 0\\
0& 1& 0& 0\\
0& 0& 1& 0\\
0& 0& 0& 0\\
\end{bmatrix}
\begin{bmatrix}
x_{t}\\y_{t}\\ \theta_{t}\\ v_{t}
\end{bmatrix}
+
\begin{bmatrix}
\cos(\theta_t)dt& 0 \\
\sin(\theta_t)dt& 0\\
0& dt\\
1& 0\\
\end{bmatrix}
\begin{bmatrix}
v_{t}\\w_{t}
\end{bmatrix}
\end{align}
$$
即这个机器人配了一个轮速计和一个$MEMS$陀螺仪，从而能够获得输入侧的角速度$w_t$和速度$v_t$. 则机器人模型的误差来自两方面：

- 传感器获得的$w_t,v_t$并不是准确的，在实际过程中我们只能拿到不准确的$w_t,v_t$, 因而它们只能认为做先验，在后续融合时矫正。
- 模型并不是准确的，即便拥有准确的$w_t,v_t$, 模型推出的$\boldsymbol{x}_{t+1}$也会和实际情况有所出入。

> 我们在仿真时不考虑模型的不确定性，因为$ground\_truth$需要是一个直观的理论曲线，不过这只是关乎$ground\_truth$的轨迹样子，忽略这误差不影响整个算法原理上的表述。

##### 观测模型

在地图中有一系列路标$landmark_i$， 机器人能够检测距机器人一定距离内的路标距机器人自身的距离$l_i=l_{true}+\sigma$, 即机器人在时间$t$内能够拿到带有误差的$w_t,u_t,\{l_i(t)\}$三个量。

##### 粒子滤波

- 首先根据状态的协方差（这是个超参数）生成一系列粒子，每个粒子表示一个状态$p=[x,y,\theta,v]$, 
- 对于每个时间戳
  - 用状态模型更新每一个粒子，即$\boldsymbol{\bar{x}}_{t+1}=Ax_t+Bu_t$, 其中$u_t$是个带噪声$\varepsilon$的输入量。对每个粒子有不同的噪声$\varepsilon$, 注意到粒子的噪声保持独立，否则后续的重采样步骤会产生大量重复粒子。
  - 对每个粒子$\boldsymbol{\bar{x}}_{t+1}$用观测模型打分。根据预先估计的观测模型的误差$\sigma$来判断在状态$\boldsymbol{\bar{x}}_{t+1}$下观测$\{l_i\}$出现的概率是大是小，即利用似然函数$\begin{align} L(x)=\prod_{i=1}^K p(l_i|\bar{x}_{t+1}) \end{align}$（参考高斯分布的推导）, 其中$p(l_i|\bar{x}_{t+1})$可以是以$\bar{x}_{t+1}$到路标$i$的距离为期望，$\sigma$为方差的概率密度函数在$l_i$处的取值（这即表示在$\boldsymbol{\bar{x}}_{t+1}$下出现这样观测的可能性）
  - 对每个粒子的$L(x)$进行归一化，得到打分$w$
  - 根据$\boldsymbol{w}\boldsymbol{w}^T$内积判断有多少比例的粒子因为$\omega$过低无效，选择是否进行重采样。重采样后粒子发生变化。
  - 选择$w$最大的作为状态，重采样后的粒子集进行下一轮更新$\boldsymbol{\bar{x}}_{t+1}=Ax_t+Bu_t$。

